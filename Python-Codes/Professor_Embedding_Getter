import ps as ps
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import json
import csv
import mysql.connector

mydb = mysql.connector.connect(
  host="localhost",
  user="root",
  password="",
  database=""
)
mydb.rollback()
mycursor = mydb.cursor()

df = pd.read_excel(r"C:\Users\Maro\Desktop\paperID.xlsx", sheet_name='paperID')
authorIDlist=list(df['paperId'])
linkList=[]
workList=[]
newauthorIDlist = [x for x in authorIDlist if pd.isnull(x) == False]

while True:
    try:
        linkList.append("https://api.semanticscholar.org/graph/v1/paper/"+(newauthorIDlist.pop(0))+"?fields=embedding")
    except IndexError:
        break



for i in range(len(linkList)):
    url = linkList.pop()
    res = requests.get(url)
    res.raise_for_status()
    soup= BeautifulSoup(res.text,"lxml")
    datas = soup.get_text()
    data = datas
    person_dict = json.loads(datas)
    person_num = person_dict['paperId']
    a = str(person_num)
    p = person_dict["embedding"]
    j = p["model"]
    k = str(p["vector"])
    print(person_num)
    sql = "INSERT INTO vectors (paperID, model, vector) VALUES (%s, %s, %s)"
    val = (a,j,k)
    mycursor.execute(sql, val)
    mydb.commit()
    if len(linkList)%85==0:
        print("length of Linklist:",len(linkList))
        print("Code in sleep...")
        time.sleep(350)




mydb.close()
