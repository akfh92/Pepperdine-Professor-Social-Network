import ps as ps
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import json
import csv
import mysql.connector

mydb = mysql.connector.connect(
  host="localhost",
  user="root",
  password="",
  database=""
)
mydb.rollback()
mycursor = mydb.cursor()

df = pd.read_excel(r"C:\Users\Maro\Desktop\plist.xlsx", sheet_name='paperlist')
authorIDlist=list(df['paperId'])
linkList=[]
workList=[]
# remove null from the authorID list
newauthorIDlist = [x for x in authorIDlist if pd.isnull(x) == False]


while True:
    try:
        linkList.append("https://api.semanticscholar.org/graph/v1/paper/"+(newauthorIDlist.pop(0))+"?fields=fieldsOfStudy")
    except IndexError:
        break



for i in range(len(linkList)):
    url = linkList.pop()
    res = requests.get(url)
    res.raise_for_status()
    soup= BeautifulSoup(res.text,"lxml")
    datas = soup.get_text()
    data = datas
    person_dict = json.loads(datas)
    pid= person_dict['paperId']
    a = str(pid)
    p = str(person_dict["fieldsOfStudy"])
    sql = "INSERT INTO fieldstudy (paperID, fs) VALUES (%s, %s)"
    val = (a,p)
    mycursor.execute(sql, val)
    mydb.commit()
    print(a)
    if len(linkList)%85==0:
        print("length of Linklist:",len(linkList))
        print("Code in sleep...")
        time.sleep(350)
